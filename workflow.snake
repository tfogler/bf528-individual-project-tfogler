import pandas

sample_csv = pandas.read_csv('sample_info.csv', index_col='name')
CONDITIONS = set(sample_csv['condition'].tolist())
REPS = set(sample_csv['replicate'].tolist())
READS = set(sample_csv['read'].tolist())

rule all:
	input:
		expand('results/{condition}{rep}_{read}_fastqc.html',
		 condition = CONDITIONS,
		 rep = REPS,
		 read = READS
		),
		'results/multiqc_report.html',
		expand("results/{condition}_{rep}.aligned.bam", condition=CONDITIONS, rep=REPS),
		expand("results/{condition}_{rep}_flagstats.txt", condition=CONDITIONS, rep=REPS),
		expand("materials/{condition}{rep}_{reads}.fastq.gz", condition=CONDITIONS, rep=REPS,
		 reads=READS),
		"materials/GRCh38.gtf",
		"verse_counts.tsv"

	
rule fastqc:
	input:
		'materials/{condition}rep{rep}_{read}.fastq.gz'
	output:
		'results/{condition}rep{rep}_{read}_fastqc.html'
	params:
		outdir = 'results/'
	threads: 4
	conda:
		'envs/fastqc_env.yml'
	shell:
		'''
		fastqc {input} -o {params.outdir}
		'''

rule multiqc:
	input:
		html=expand('results/{condition}{rep}_{read}_fastqc.html', 
		condition=CONDITIONS,
		rep=REPS,
		read=READS
		),
		zip=expand('results/{condition}{rep}_{read}_fastqc.zip', 
		condition=CONDITIONS,
		rep=REPS,
		read=READS
		)
	output:
		multiqc = 'results/multiqc_report.html'
	params:
		outdir = 'results/'
	conda:
		'envs/multiqc_env.yml'
	shell:
		'''
		multiqc results/ -o {params.outdir}
		'''

# Rule to download GRCh38 genome
rule get_GRCh38:
	output:
		"materials/GRCh38.fa.gz"
	shell:
		'''
		wget -O {output} https://ftp.ebi.ac.uk/pub/databases/gencode/Gencode_human/release_45/GRCh38.primary_assembly.genome.fa.gz
		'''

# rule to unzip the genome FASTA file
rule unzip_fasta:
	input:
		gz="materials/GRCh38.fa.gz"
	output:
		fa="materials/GRCh38.fa"
	shell:
		'''
		gunzip -c {input.gz} > {output.fa}
		'''
# Rule to download GRCh38 GTF annotation file
rule get_GRCh38_gtf:
	output:
		"materials/GRCh38.gtf.gz"
	shell:
		'''
		ftp_path = "https://ftp.ebi.ac.uk/pub/databases/gencode/Gencode_human/release_45/gencode.v45.primary_assembly.annotation.gtf.gz"
		'''

# rule to unzip the genome GTF annotation file
rule unzip_gtf:
	input:
		gz="materials/GRCh38.gtf.gz"
	output:
		gtf="materials/GRCh38.gtf"
	shell:
		'''
		gunzip -c {input.gz} > {output.gtf}
		'''

# we want to sort the alignments from bowtie2_align
rule samtools_sort:
	input:
		'results/{condition}_{rep}.bam'
	output:
		'results/{condition}_{rep}.aligned.bam'
	conda:
		'envs/samtools_env.yml'
	shell:
		'''
		samtools sort {input} -o {output}
		rm {input}
		'''

# Define the rule for building HISAT2 index from the human genome FASTA file
rule build_hisat_index:
	input:
		fasta = 'materials/GRCh38.fa'  # Path to human genome FASTA file
	output:
		hisat_index = "results/GRCh38.1.ht2",  # Output file for the HISAT2 index
	params:
		hisat_index_prefix = ("results/GRCh38")  # Output directory for the HISAT2 index
	conda:
		'envs/hisat2_env.yml'
	threads: 16
	shell:
		'''
		mkdir -p {output.hisat_index_dir}
		hisat2-build -f {input.fasta} {params.hisat_index_prefix}
		'''

# Define the rule for aligning paired-end FASTQ files to the HISAT2 index
rule align_reads:
	input:
		hisat_index_file = "results/GRCh38.1.ht2", # File of the HISAT2 index
		fastq1='materials/{condition}rep{rep}_R1.fastq.gz', # Path to fwd reads
		fastq2='materials/{condition}rep{rep}_R2.fastq.gz' # Path to rvs reads
	output:
		bam_file = "results/{condition}_rep{rep}.bam"  # Output path for the aligned BAM file
	params:
		index_prefix = "results/GRCh38"  # Prefix of the HISAT2 index
	conda:
		'envs/hisat2_env.yml'
	threads: 16
	shell:
		'''
		hisat2 -x {params.index_prefix} \
			   -1 {input.fastq1} \
			   -2 {input.fastq2} \
		| samtools view -b > {output.bam_file}
		'''

# Rule to generate flagstat from aligned BAM files using samtools
rule samtools_flagstat:
	input:
		bam="results/{condition}_{rep}.aligned.bam"
	output:
		flagstat="results/{condition}_{rep}_flagstats.txt"
	conda:
		'envs/samtools_env.yml'
	shell:
		"samtools flagstat {input.bam} > {output.flagstat}"


# Rule to use VERSE to generate gene counts from aligned BAM files
rule generate_counts_with_verse:
	input:
		bam_file = "results/{condition}_{rep}.aligned.bam",  # Path to the aligned BAM file
		gtf = "materials/GRCh38.gtf"  # Path to the gene annotation file
	output:
		tsv_file = "results/{condition}_{rep}_counts.tsv"  # Output path for the TSV file
	conda:
		"envs/verse_env.yml"
	shell:
		"""
		verse quant -a {input.gtf} -o {output.tsv_file} -t transcriptome \
			-s gene_id -i {input.bam_file}
		"""

# Rule to combine all count files into one output file
rule combine_verse_counts:
	input:
		# Paths to individual count files
		count_files = expand("results/{condition}_{rep}_counts.tsv",
		  condition=CONDITIONS,
		  rep=REPS)
	output:
		combined_counts = "verse_counts.tsv"  # Output path for the combined counts file
	run:
		# Create an empty list to store DataFrames
		dfs = []
		
		# Iterate through input count files and read them into DataFrames
		for count_file in input.count_files:
			df = pd.read_csv(count_file, sep="\t", index_col=0)
			dfs.append(df)
		
		# Concatenate all DataFrames along the columns (axis=1)
		combined_df = pd.concat(dfs, axis=1, join="outer")
		
		# Write the combined DataFrame to the output file
		combined_df.to_csv(output.combined_counts, sep="\t")
